{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afd997de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import find_peaks\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix,f1_score, roc_auc_score\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,LabelEncoder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau,CosineAnnealingLR\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "import torch.optim as optim\n",
    "from catboost import CatBoostClassifier\n",
    "import neurokit2 as nk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available()) \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e1d24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(full_path):\n",
    "  dataset = []\n",
    "  labels = []\n",
    "  for file_name in os.listdir(full_path):\n",
    "    if file_name.endswith('.hea'):\n",
    "      continue\n",
    "    label = os.path.basename(os.path.dirname(full_path))\n",
    "    labels.append(label)\n",
    "    data = np.fromfile((os.path.join(full_path,file_name)),dtype = np.int16)\n",
    "    dataset.append(data)\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df['label'] = labels\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f473e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\O'\n",
      "C:\\Users\\richk\\AppData\\Local\\Temp\\ipykernel_18184\\4126605693.py:2: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  df2 =create_db(full_path=\"C:\\\\Users\\\\richk\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\2_Special_Form_VTTdP\\\\frag\")\n"
     ]
    }
   ],
   "source": [
    "df1 = create_db(full_path=\"C:\\\\Users\\\\richk\\\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\1_Dangerous_VFL_VF\\\\frag\")\n",
    "df2 =create_db(full_path=\"C:\\\\Users\\\\richk\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\2_Special_Form_VTTdP\\\\frag\")\n",
    "df3 = create_db(full_path=\"C:\\\\Users\\\\richk\\\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\3_Threatening_VT\\\\frag\")\n",
    "df4 =create_db(full_path=\"C:\\\\Users\\\\richk\\\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\4_Potential_Dangerous\\\\frag\")\n",
    "df5 = create_db(full_path=\"C:\\\\Users\\\\richk\\\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\5_Supraventricular\\\\frag\")\n",
    "df6 =create_db(full_path=\"C:\\\\Users\\\\richk\\\\OneDrive\\\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\\\6_Sinus_rhythm\\\\frag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7cb5863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richk\\AppData\\Local\\Temp\\ipykernel_18184\\2629379934.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_dataset = full_dataset.replace(['1_Dangerous_VFL_VF','2_Special_Form_VTTdP','3_Threatening_VT','4_Potential_Dangerous','5_Supraventricular','6_Sinus_rhythm'],[0,1,2,3,4,5])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "      <th>720</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "      <td>178</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>171</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>168</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>198</td>\n",
       "      <td>202</td>\n",
       "      <td>204</td>\n",
       "      <td>202</td>\n",
       "      <td>199</td>\n",
       "      <td>194</td>\n",
       "      <td>191</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-191</td>\n",
       "      <td>-191</td>\n",
       "      <td>-192</td>\n",
       "      <td>-195</td>\n",
       "      <td>-200</td>\n",
       "      <td>-204</td>\n",
       "      <td>-202</td>\n",
       "      <td>-197</td>\n",
       "      <td>-189</td>\n",
       "      <td>-179</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>176</td>\n",
       "      <td>157</td>\n",
       "      <td>136</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-20</td>\n",
       "      <td>-48</td>\n",
       "      <td>-69</td>\n",
       "      <td>-86</td>\n",
       "      <td>-99</td>\n",
       "      <td>-110</td>\n",
       "      <td>-120</td>\n",
       "      <td>-130</td>\n",
       "      <td>-139</td>\n",
       "      <td>-149</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>-3</td>\n",
       "      <td>-29</td>\n",
       "      <td>-59</td>\n",
       "      <td>-89</td>\n",
       "      <td>-115</td>\n",
       "      <td>-135</td>\n",
       "      <td>-149</td>\n",
       "      <td>-158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>112</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td>126</td>\n",
       "      <td>132</td>\n",
       "      <td>137</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>-204</td>\n",
       "      <td>-209</td>\n",
       "      <td>-211</td>\n",
       "      <td>-213</td>\n",
       "      <td>-216</td>\n",
       "      <td>-217</td>\n",
       "      <td>-216</td>\n",
       "      <td>-214</td>\n",
       "      <td>-211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217</td>\n",
       "      <td>224</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>133</td>\n",
       "      <td>127</td>\n",
       "      <td>121</td>\n",
       "      <td>115</td>\n",
       "      <td>110</td>\n",
       "      <td>104</td>\n",
       "      <td>96</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>-29</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-30</td>\n",
       "      <td>-29</td>\n",
       "      <td>-28</td>\n",
       "      <td>-30</td>\n",
       "      <td>-33</td>\n",
       "      <td>-36</td>\n",
       "      <td>-35</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>-75</td>\n",
       "      <td>-75</td>\n",
       "      <td>-74</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-75</td>\n",
       "      <td>-73</td>\n",
       "      <td>-71</td>\n",
       "      <td>-68</td>\n",
       "      <td>-66</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>-73</td>\n",
       "      <td>-75</td>\n",
       "      <td>-73</td>\n",
       "      <td>-70</td>\n",
       "      <td>-69</td>\n",
       "      <td>-71</td>\n",
       "      <td>-72</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "      <td>-72</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-26</td>\n",
       "      <td>-23</td>\n",
       "      <td>-21</td>\n",
       "      <td>-20</td>\n",
       "      <td>-19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-17</td>\n",
       "      <td>-18</td>\n",
       "      <td>-19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>-3</td>\n",
       "      <td>-9</td>\n",
       "      <td>-13</td>\n",
       "      <td>-16</td>\n",
       "      <td>-16</td>\n",
       "      <td>-17</td>\n",
       "      <td>-14</td>\n",
       "      <td>-11</td>\n",
       "      <td>-9</td>\n",
       "      <td>-8</td>\n",
       "      <td>...</td>\n",
       "      <td>-9</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows √ó 722 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  712  713  714  \\\n",
       "0     180  178  175  172  171  173  175  174  168  156  ...  192  198  202   \n",
       "1    -191 -191 -192 -195 -200 -204 -202 -197 -189 -179  ...  194  176  157   \n",
       "2     -20  -48  -69  -86  -99 -110 -120 -130 -139 -149  ...   18   -3  -29   \n",
       "3      89   99  107  112  117  121  126  132  137  142  ... -204 -209 -211   \n",
       "4     217  224  227  228  229  230  232  234  235  235  ...  140  133  127   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1011  -29  -30  -30  -30  -29  -28  -30  -33  -36  -35  ...   25   26   27   \n",
       "1012  -75  -75  -74  -75  -76  -75  -73  -71  -68  -66  ...   -2   -1    3   \n",
       "1013  -73  -75  -73  -70  -69  -71  -72  -73  -73  -72  ...   38   36   34   \n",
       "1014   16   19   25   27   27   24   21   19   20   21  ...  -26  -23  -21   \n",
       "1015   -3   -9  -13  -16  -16  -17  -14  -11   -9   -8  ...   -9   -7   -5   \n",
       "\n",
       "      715  716  717  718  719  720  label  \n",
       "0     204  202  199  194  191  188      0  \n",
       "1     136  109   78   45   11  -20      0  \n",
       "2     -59  -89 -115 -135 -149 -158      0  \n",
       "3    -213 -216 -217 -216 -214 -211      0  \n",
       "4     121  115  110  104   96   88      0  \n",
       "...   ...  ...  ...  ...  ...  ...    ...  \n",
       "1011   26   22   17   12    5    1      5  \n",
       "1012    4    5    3    1    1    3      5  \n",
       "1013   35   36   37   35   31   29      5  \n",
       "1014  -20  -19  -18  -17  -18  -19      5  \n",
       "1015   -3   -3   -2   -1    0    1      5  \n",
       "\n",
       "[1016 rows x 722 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = pd.concat([df1,df2,df3, df4, df5, df6], ignore_index=True)\n",
    "full_dataset = full_dataset.replace(['1_Dangerous_VFL_VF','2_Special_Form_VTTdP','3_Threatening_VT','4_Potential_Dangerous','5_Supraventricular','6_Sinus_rhythm'],[0,1,2,3,4,5])\n",
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "057d015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_signals(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = np.zeros_like(data, dtype=np.float32)\n",
    "    for i in range(data.shape[0]):\n",
    "        data_normalized[i] = scaler.fit_transform(data[i].reshape(-1, 1)).reshape(-1)\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f850cf5",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "73563862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db1(full_path, numb=15):\n",
    "  combined_df = pd.DataFrame(columns=[i for i in range(numb+1)] + ['label'])\n",
    "  for file_name in os.listdir(full_path):\n",
    "    label = os.path.basename(os.path.dirname(full_path))\n",
    "    data = pd.read_csv(os.path.join(full_path,file_name), header=None)\n",
    "    data = data[0].tolist()\n",
    "    row = data[:len(data)] + [label]\n",
    "    try:\n",
    "        combined_df.loc[len(combined_df)] = row\n",
    "    except:\n",
    "        print(row, len(row))\n",
    "  return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98edf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = create_db1(r\"C:\\Users\\richk\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\1_Dangerous_VFL_VF\\15_2\")\n",
    "df12 = create_db1(r\"C:\\Users\\richk\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\2_Special_Form_VTTdP\\15_2\")\n",
    "df13 = create_db1(r\"C:\\Users\\richk\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\3_Threatening_VT\\15_2\")\n",
    "df14 = create_db1(r\"C:\\Users\\richk\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\4_Potential_Dangerous\\15_2\")\n",
    "df15 = create_db1(r\"C:\\Users\\richk\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\5_Supraventricular\\15_2\")\n",
    "df16 = create_db1(r\"C:\\Users\\richk\\OneDrive\\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\\ecg-fragment-database-for-the-exploration-of-dangerous-arrhythmia-1.0.0\\6_Sinus_rhythm\\15_2\")\n",
    "full_dataset_spec = pd.concat([df11,df12,df13, df14, df15, df16], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97983b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500509</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.020108</td>\n",
       "      <td>0.353323</td>\n",
       "      <td>0.104229</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1_Dangerous_VFL_VF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501034</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.446605</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>1_Dangerous_VFL_VF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.504155</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>0.275896</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1_Dangerous_VFL_VF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>0.427695</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>1_Dangerous_VFL_VF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.501845</td>\n",
       "      <td>0.016170</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.059468</td>\n",
       "      <td>0.388257</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>1_Dangerous_VFL_VF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.532172</td>\n",
       "      <td>0.078659</td>\n",
       "      <td>0.163871</td>\n",
       "      <td>0.124378</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>6_Sinus_rhythm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0.527665</td>\n",
       "      <td>0.083837</td>\n",
       "      <td>0.161463</td>\n",
       "      <td>0.140240</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>6_Sinus_rhythm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0.530357</td>\n",
       "      <td>0.116369</td>\n",
       "      <td>0.161673</td>\n",
       "      <td>0.090933</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>6_Sinus_rhythm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.588906</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>0.022378</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.027613</td>\n",
       "      <td>0.039003</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>6_Sinus_rhythm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.582093</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.016375</td>\n",
       "      <td>0.044085</td>\n",
       "      <td>0.020337</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.028766</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>6_Sinus_rhythm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.500509  0.003944  0.001465  0.020108  0.353323  0.104229  0.004624   \n",
       "1     0.501034  0.000958  0.000307  0.004485  0.002104  0.446605  0.029388   \n",
       "2     0.504155  0.008499  0.001189  0.004717  0.003827  0.197160  0.275896   \n",
       "3     0.501434  0.008014  0.000634  0.009609  0.013945  0.427695  0.023103   \n",
       "4     0.501845  0.016170  0.000965  0.005679  0.059468  0.388257  0.016360   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1011  0.532172  0.078659  0.163871  0.124378  0.002418  0.004443  0.005249   \n",
       "1012  0.527665  0.083837  0.161463  0.140240  0.008756  0.006642  0.005331   \n",
       "1013  0.530357  0.116369  0.161673  0.090933  0.006801  0.003343  0.013240   \n",
       "1014  0.588906  0.009806  0.009397  0.024792  0.029349  0.046225  0.022378   \n",
       "1015  0.582093  0.036334  0.016375  0.044085  0.020337  0.038263  0.024644   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "0     0.003921  0.001784  0.000782  0.001613  0.000220  0.000066  0.001069   \n",
       "1     0.000150  0.000578  0.000133  0.005371  0.001318  0.000123  0.000043   \n",
       "2     0.000279  0.000506  0.000080  0.000267  0.003288  0.000013  0.000036   \n",
       "3     0.000275  0.000387  0.000760  0.005770  0.000616  0.000255  0.000260   \n",
       "4     0.000474  0.000795  0.002133  0.001301  0.000734  0.000119  0.000774   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1011  0.015258  0.010414  0.012074  0.007973  0.010889  0.009734  0.009806   \n",
       "1012  0.012771  0.007970  0.008241  0.007373  0.006787  0.006855  0.006800   \n",
       "1013  0.014657  0.003945  0.009201  0.008982  0.008767  0.007886  0.008111   \n",
       "1014  0.017541  0.027613  0.039003  0.027436  0.027174  0.037489  0.037989   \n",
       "1015  0.024400  0.021569  0.024308  0.022926  0.029258  0.042229  0.028766   \n",
       "\n",
       "            14        15               label  \n",
       "0     0.002011  0.000333  1_Dangerous_VFL_VF  \n",
       "1     0.000631  0.006771  1_Dangerous_VFL_VF  \n",
       "2     0.000043  0.000045  1_Dangerous_VFL_VF  \n",
       "3     0.001259  0.005983  1_Dangerous_VFL_VF  \n",
       "4     0.003706  0.001220  1_Dangerous_VFL_VF  \n",
       "...        ...       ...                 ...  \n",
       "1011  0.005549  0.007114      6_Sinus_rhythm  \n",
       "1012  0.005388  0.003880      6_Sinus_rhythm  \n",
       "1013  0.008110  0.007626      6_Sinus_rhythm  \n",
       "1014  0.037566  0.017335      6_Sinus_rhythm  \n",
       "1015  0.021813  0.022600      6_Sinus_rhythm  \n",
       "\n",
       "[1016 rows x 17 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(full_dataset_spec) \n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "row_sums = df[numeric_columns].sum(axis=1)\n",
    "\n",
    "if (row_sums == 0).any():\n",
    "    raise ValueError(\"–ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ø–µ–∫—Ç—Ä—ã –∏–º–µ—é—Ç –Ω—É–ª–µ–≤—É—é —Å—É–º–º—É –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–µ–π!\")\n",
    "\n",
    "\n",
    "df_normalized = df.copy()\n",
    "df_normalized[numeric_columns] = df[numeric_columns].div(row_sums, axis=0)\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3230ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMM(data):\n",
    "    return np.min(data), np.max(data), round(np.mean(data),2)\n",
    "\n",
    "def zero_cross(data):\n",
    "  ZC_count = 0\n",
    "  for i in range(len(data)-1):\n",
    "    if data[i] > 0  and data[i+1] < 0:\n",
    "      ZC_count += 1\n",
    "    if data[i] < 0 and data[i+1] > 0:\n",
    "      ZC_count += 1\n",
    "  return ZC_count\n",
    "\n",
    "def extract_frequency_features(data, fs):\n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞\n",
    "    data = data - np.mean(data)\n",
    "\n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º FFT\n",
    "    N = len(data)\n",
    "    spectrum = np.abs(fft(data))[:N // 2]   # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã\n",
    "    freqs = np.linspace(0, fs / 2, N // 2)\n",
    "\n",
    "    # –ù–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–µ–∫—Ç—Ä (–¥–ª—è —ç–Ω—Ç—Ä–æ–ø–∏–∏ –∏ centroid)\n",
    "    psd = spectrum ** 2\n",
    "    psd_norm = psd / np.sum(psd + 1e-12)  # +1e-12 ‚Äî —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ 0\n",
    "\n",
    "    # üîπ 1. Spectral entropy\n",
    "    spec_entropy = entropy(psd_norm)\n",
    "\n",
    "    # üîπ 2. Dominant frequency\n",
    "    dom_freq = freqs[np.argmax(psd)]\n",
    "\n",
    "    # üîπ 3. Spectral centroid\n",
    "    centroid = np.sum(freqs * psd_norm)\n",
    "\n",
    "    return spec_entropy, dom_freq, centroid\n",
    "\n",
    "\n",
    "def heart_rate(data,fs):\n",
    "    peaks, _ = find_peaks(data, distance=fs*0.01, height=np.mean(data) + np.std(data))\n",
    "\n",
    "    rr_intervals_samples = np.diff(peaks)\n",
    "    rr_intervals_sec = rr_intervals_samples / fs\n",
    "    heart_rates = 60 / rr_intervals_sec\n",
    "\n",
    "    mean_hr = np.mean(heart_rates)\n",
    "\n",
    "    return round(mean_hr, 2)\n",
    "\n",
    "def preproc_file(full_path, fs = 360):\n",
    "  features =[]\n",
    "  for file_name in os.listdir(full_path):\n",
    "    if file_name.endswith('.hea'):\n",
    "      continue\n",
    "    data = np.fromfile((os.path.join(full_path,file_name)), dtype = np.int16)\n",
    "    min_v , max_v, mean_v = MMM(data)\n",
    "    HR = heart_rate(data,fs)\n",
    "    spec_entropy, dom_freq, centroid = extract_frequency_features(data, fs)\n",
    "    ZC = zero_cross(data)\n",
    "    features.append({\n",
    "        \"file\": file_name,\n",
    "        \"label\": os.path.basename(os.path.dirname(full_path)),\n",
    "        \"hr\": HR,\n",
    "        \"min\": min_v,\n",
    "        \"max\": max_v,\n",
    "        \"mean\": mean_v,\n",
    "        \"zero_cross\": ZC,\n",
    "        \"entropy\": spec_entropy,\n",
    "        \"dom_freq\": dom_freq,\n",
    "        \"centroid\": centroid\n",
    "    })\n",
    "  return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35586ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_from_dataframe(df, fs=360):\n",
    "    features = []\n",
    "    \n",
    "    # –ò–¥–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º —Ç–∞–±–ª–∏—Ü—ã\n",
    "    for index, row in df.iterrows():\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å–∏–≥–Ω–∞–ª –∏–∑ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º 'label'\n",
    "        signal = row.drop('label').values  # –°–∏–≥–Ω–∞–ª ‚Äî —ç—Ç–æ –≤—Å–µ, –∫—Ä–æ–º–µ 'label'\n",
    "        \n",
    "        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        min_v, max_v, mean_v = MMM(signal)\n",
    "        HR = heart_rate(signal, fs)\n",
    "        spec_entropy, dom_freq, centroid = extract_frequency_features(signal, fs)\n",
    "        ZC = zero_cross(signal)\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å–ø–∏—Å–æ–∫\n",
    "        features.append({\n",
    "            \"hr\": HR,\n",
    "            \"min\": min_v,\n",
    "            \"max\": max_v,\n",
    "            \"mean\": mean_v,\n",
    "            \"zero_cross\": ZC,\n",
    "            \"entropy\": spec_entropy,\n",
    "            \"dom_freq\": dom_freq,\n",
    "            \"centroid\": centroid\n",
    "        })\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "    features_df = pd.DataFrame(features)\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–π–±–ª—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ DataFrame\n",
    "    features_df['label'] = df['label']\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4bf88918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "processed_df = preproc_from_dataframe(full_dataset)\n",
    "processed_df = processed_df.drop('label',axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dec8edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>zero_cross</th>\n",
       "      <th>entropy</th>\n",
       "      <th>dom_freq</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1435.96</td>\n",
       "      <td>-299.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>-17.68</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.812203</td>\n",
       "      <td>4.011142</td>\n",
       "      <td>4.177260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017.37</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.021716</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>5.329754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316.72</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>21.59</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.415667</td>\n",
       "      <td>5.515320</td>\n",
       "      <td>5.264376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1194.15</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.734859</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>5.537361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010.44</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.086808</td>\n",
       "      <td>4.512535</td>\n",
       "      <td>4.728101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2004.91</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-11.24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.388714</td>\n",
       "      <td>1.504178</td>\n",
       "      <td>4.707126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1500.30</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.471035</td>\n",
       "      <td>1.504178</td>\n",
       "      <td>5.008852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2231.71</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.938972</td>\n",
       "      <td>2.506964</td>\n",
       "      <td>6.313203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>76.33</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.506330</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>12.115905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>77.17</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.702971</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>11.834435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hr    min    max   mean  zero_cross   entropy  dom_freq   centroid\n",
       "0     1435.96 -299.0  238.0 -17.68        16.0  0.812203  4.011142   4.177260\n",
       "1     1017.37 -228.0  260.0   7.80        19.0  1.021716  5.013928   5.329754\n",
       "2      316.72 -210.0  320.0  21.59        20.0  1.415667  5.515320   5.264376\n",
       "3     1194.15 -233.0  207.0   1.44        19.0  1.734859  5.013928   5.537361\n",
       "4     1010.44 -230.0  235.0   3.64        17.0  2.086808  4.512535   4.728101\n",
       "...       ...    ...    ...    ...         ...       ...       ...        ...\n",
       "1011  2004.91 -102.0  139.0 -11.24        13.0  2.388714  1.504178   4.707126\n",
       "1012  1500.30  -83.0  117.0  -6.79        18.0  2.471035  1.504178   5.008852\n",
       "1013  2231.71  -78.0  135.0  -5.63        10.0  2.938972  2.506964   6.313203\n",
       "1014    76.33 -357.0  633.0  11.93        24.0  3.506330  5.013928  12.115905\n",
       "1015    77.17 -357.0  618.0   7.90        12.0  3.702971  5.013928  11.834435\n",
       "\n",
       "[1016 rows x 8 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = normalize_signals(processed_df.values) \n",
    "X_scaled_df = pd.DataFrame(processed_df.values,columns=processed_df.columns)\n",
    "X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fb2edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1016 entries, 0 to 1015\n",
      "Data columns (total 25 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   hr          1016 non-null   float64\n",
      " 1   min         1016 non-null   float64\n",
      " 2   max         1016 non-null   float64\n",
      " 3   mean        1016 non-null   float64\n",
      " 4   zero_cross  1016 non-null   float64\n",
      " 5   entropy     1016 non-null   float64\n",
      " 6   dom_freq    1016 non-null   float64\n",
      " 7   centroid    1016 non-null   float64\n",
      " 8   0           1016 non-null   float64\n",
      " 9   1           1016 non-null   float64\n",
      " 10  2           1016 non-null   float64\n",
      " 11  3           1016 non-null   float64\n",
      " 12  4           1016 non-null   float64\n",
      " 13  5           1016 non-null   float64\n",
      " 14  6           1016 non-null   float64\n",
      " 15  7           1016 non-null   float64\n",
      " 16  8           1016 non-null   float64\n",
      " 17  9           1016 non-null   float64\n",
      " 18  10          1016 non-null   float64\n",
      " 19  11          1016 non-null   float64\n",
      " 20  12          1016 non-null   float64\n",
      " 21  13          1016 non-null   float64\n",
      " 22  14          1016 non-null   float64\n",
      " 23  15          1016 non-null   float64\n",
      " 24  label       1016 non-null   object \n",
      "dtypes: float64(24), object(1)\n",
      "memory usage: 198.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_scaled_df = X_scaled_df.reset_index(drop=True)\n",
    "df_normalized = df_normalized.reset_index(drop=True)\n",
    "res_ = pd.concat([X_scaled_df, df_normalized], axis=1)\n",
    "res_['hr'] = res_['hr'].interpolate(method='linear')\n",
    "res_.info()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "000d2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richk\\AppData\\Local\\Temp\\ipykernel_18184\\1916515944.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  res___= res_.replace(['1_Dangerous_VFL_VF','2_Special_Form_VTTdP','3_Threatening_VT','4_Potential_Dangerous','5_Supraventricular','6_Sinus_rhythm'],[0,1,2,3,4,5])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>zero_cross</th>\n",
       "      <th>entropy</th>\n",
       "      <th>dom_freq</th>\n",
       "      <th>centroid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1435.96</td>\n",
       "      <td>-299.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>-17.68</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.812203</td>\n",
       "      <td>4.011142</td>\n",
       "      <td>4.177260</td>\n",
       "      <td>0.500509</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1017.37</td>\n",
       "      <td>-228.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.021716</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>5.329754</td>\n",
       "      <td>0.501034</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316.72</td>\n",
       "      <td>-210.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>21.59</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.415667</td>\n",
       "      <td>5.515320</td>\n",
       "      <td>5.264376</td>\n",
       "      <td>0.504155</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1194.15</td>\n",
       "      <td>-233.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.734859</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>5.537361</td>\n",
       "      <td>0.501434</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010.44</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.086808</td>\n",
       "      <td>4.512535</td>\n",
       "      <td>4.728101</td>\n",
       "      <td>0.501845</td>\n",
       "      <td>0.016170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>2004.91</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-11.24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.388714</td>\n",
       "      <td>1.504178</td>\n",
       "      <td>4.707126</td>\n",
       "      <td>0.532172</td>\n",
       "      <td>0.078659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1500.30</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.471035</td>\n",
       "      <td>1.504178</td>\n",
       "      <td>5.008852</td>\n",
       "      <td>0.527665</td>\n",
       "      <td>0.083837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2231.71</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.938972</td>\n",
       "      <td>2.506964</td>\n",
       "      <td>6.313203</td>\n",
       "      <td>0.530357</td>\n",
       "      <td>0.116369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>76.33</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.506330</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>12.115905</td>\n",
       "      <td>0.588906</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.027613</td>\n",
       "      <td>0.039003</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>77.17</td>\n",
       "      <td>-357.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.702971</td>\n",
       "      <td>5.013928</td>\n",
       "      <td>11.834435</td>\n",
       "      <td>0.582093</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.029258</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.028766</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hr    min    max   mean  zero_cross   entropy  dom_freq   centroid  \\\n",
       "0     1435.96 -299.0  238.0 -17.68        16.0  0.812203  4.011142   4.177260   \n",
       "1     1017.37 -228.0  260.0   7.80        19.0  1.021716  5.013928   5.329754   \n",
       "2      316.72 -210.0  320.0  21.59        20.0  1.415667  5.515320   5.264376   \n",
       "3     1194.15 -233.0  207.0   1.44        19.0  1.734859  5.013928   5.537361   \n",
       "4     1010.44 -230.0  235.0   3.64        17.0  2.086808  4.512535   4.728101   \n",
       "...       ...    ...    ...    ...         ...       ...       ...        ...   \n",
       "1011  2004.91 -102.0  139.0 -11.24        13.0  2.388714  1.504178   4.707126   \n",
       "1012  1500.30  -83.0  117.0  -6.79        18.0  2.471035  1.504178   5.008852   \n",
       "1013  2231.71  -78.0  135.0  -5.63        10.0  2.938972  2.506964   6.313203   \n",
       "1014    76.33 -357.0  633.0  11.93        24.0  3.506330  5.013928  12.115905   \n",
       "1015    77.17 -357.0  618.0   7.90        12.0  3.702971  5.013928  11.834435   \n",
       "\n",
       "             0         1  ...         7         8         9        10  \\\n",
       "0     0.500509  0.003944  ...  0.003921  0.001784  0.000782  0.001613   \n",
       "1     0.501034  0.000958  ...  0.000150  0.000578  0.000133  0.005371   \n",
       "2     0.504155  0.008499  ...  0.000279  0.000506  0.000080  0.000267   \n",
       "3     0.501434  0.008014  ...  0.000275  0.000387  0.000760  0.005770   \n",
       "4     0.501845  0.016170  ...  0.000474  0.000795  0.002133  0.001301   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "1011  0.532172  0.078659  ...  0.015258  0.010414  0.012074  0.007973   \n",
       "1012  0.527665  0.083837  ...  0.012771  0.007970  0.008241  0.007373   \n",
       "1013  0.530357  0.116369  ...  0.014657  0.003945  0.009201  0.008982   \n",
       "1014  0.588906  0.009806  ...  0.017541  0.027613  0.039003  0.027436   \n",
       "1015  0.582093  0.036334  ...  0.024400  0.021569  0.024308  0.022926   \n",
       "\n",
       "            11        12        13        14        15  label  \n",
       "0     0.000220  0.000066  0.001069  0.002011  0.000333      0  \n",
       "1     0.001318  0.000123  0.000043  0.000631  0.006771      0  \n",
       "2     0.003288  0.000013  0.000036  0.000043  0.000045      0  \n",
       "3     0.000616  0.000255  0.000260  0.001259  0.005983      0  \n",
       "4     0.000734  0.000119  0.000774  0.003706  0.001220      0  \n",
       "...        ...       ...       ...       ...       ...    ...  \n",
       "1011  0.010889  0.009734  0.009806  0.005549  0.007114      5  \n",
       "1012  0.006787  0.006855  0.006800  0.005388  0.003880      5  \n",
       "1013  0.008767  0.007886  0.008111  0.008110  0.007626      5  \n",
       "1014  0.027174  0.037489  0.037989  0.037566  0.017335      5  \n",
       "1015  0.029258  0.042229  0.028766  0.021813  0.022600      5  \n",
       "\n",
       "[1016 rows x 25 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res___= res_.replace(['1_Dangerous_VFL_VF','2_Special_Form_VTTdP','3_Threatening_VT','4_Potential_Dangerous','5_Supraventricular','6_Sinus_rhythm'],[0,1,2,3,4,5])\n",
    "res___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd9434",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16620bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0030, 0.0139, 0.0059, 0.0076, 0.0094, 0.0050], device='cuda:0') [0.0029673590503570516, 0.013888888886959877, 0.005917159762963481, 0.007575757575183654, 0.009433962263260948, 0.0049999999997499996]\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # –¢–µ–Ω–∑–æ—Ä –≤–µ—Å–æ–≤ [n_classes]\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce(inputs, targets)  # [batch_size]\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            # –£–º–Ω–æ–∂–∞–µ–º CE –Ω–∞ alpha –î–û –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏\n",
    "            ce_loss = ce_loss * self.alpha[targets]\n",
    "        \n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "    \n",
    "support = [337, 72, 169, 132, 106, 200]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "epsilon = 1e-8\n",
    "weights_cat = [1. / (s + epsilon) for s in support]\n",
    "weights = torch.tensor(weights_cat, dtype=torch.float32).to(device)\n",
    "print(weights,weights_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a8233639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Specnaz_gru_plus_norm(nn.Module):\n",
    "    def __init__(self, input_size=721, num_classes=6):\n",
    "        super(Specnaz_gru_plus_norm, self).__init__()\n",
    "\n",
    "        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π   \n",
    "        self.conv1 = nn.Conv1d(1,16, kernel_size=5,padding = 2)\n",
    "        self.layer_norm1 = nn.LayerNorm(16)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–∫–∏\n",
    "        self.gelu = nn.SiLU()\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(16,32,kernel_size=5,padding =2 )\n",
    "        self.layer_norm2 = nn.LayerNorm(32) \n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "        self.pool = nn.AvgPool1d(kernel_size=2,stride =2 )\n",
    "\n",
    "        # GRU —Å–ª–æ–∏\n",
    "        self.gru1 = nn.GRU(input_size=32, hidden_size=64, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm3 = nn.LayerNorm(128)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "\n",
    "        self.gru2 = nn.GRU(input_size=128, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm4 = nn.LayerNorm(512)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–≥–æ qsdqdqdqd\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "\n",
    "        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.skip_con = nn.Linear(128, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  \n",
    "\n",
    "        x = self.conv1(x)   \n",
    "        x = x.permute(0, 2, 1)       \n",
    "        x = self.layer_norm1(x)      \n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "\n",
    "        x = self.conv2(x)   \n",
    "        x = x.permute(0, 2, 1)       \n",
    "        x = self.layer_norm2(x)      \n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.permute(0, 2, 1)     \n",
    "        x = self.pool(x)             \n",
    "        x = x.permute(0, 2, 1)       \n",
    "\n",
    "        x1, _ = self.gru1(x)\n",
    "        x1 = self.layer_norm3(x1)\n",
    "        x1= self.dropout3(x1) \n",
    "\n",
    "        x2, _ = self.gru2(x1)\n",
    "        x2 = self.layer_norm4(x2)\n",
    "        x2 = self.gelu(x2)\n",
    "        x2 = self.dropout4(x2)\n",
    "\n",
    "        x1 = self.skip_con(x1)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        x = x[:, -1, :]\n",
    "        output = self.fc(x) \n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bd388298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader_nn:\n\u001b[32m     99\u001b[39m     inputs, labels = inputs.to(device), labels.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m    102\u001b[39m     val_loss_epoch.append(loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mSpecnaz_gru_plus_norm.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     51\u001b[39m x1 = \u001b[38;5;28mself\u001b[39m.layer_norm3(x1)\n\u001b[32m     52\u001b[39m x1= \u001b[38;5;28mself\u001b[39m.dropout3(x1) \n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m x2, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgru2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m x2 = \u001b[38;5;28mself\u001b[39m.layer_norm4(x2)\n\u001b[32m     56\u001b[39m x2 = \u001b[38;5;28mself\u001b[39m.gelu(x2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\richk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1393\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28mself\u001b[39m.check_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[32m   1392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1393\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1405\u001b[39m     result = _VF.gru(\n\u001b[32m   1406\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1407\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1414\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1415\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===\n",
    "\n",
    "\n",
    "X_nn = full_dataset.drop(columns=['label'])\n",
    "y_nn = full_dataset['label']\n",
    "X_cat = res___.drop(columns=['label'])\n",
    "y_cat = res___['label']\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_nn = label_encoder.fit_transform(y_nn)\n",
    "y_cat = label_encoder.transform(y_cat)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train+val –∏ test\n",
    "X_train_val_nn, X_test_nn, y_train_val_nn, y_test_nn = train_test_split(\n",
    "    X_nn, y_nn, test_size=0.25, random_state=42, stratify=y_nn)\n",
    "X_train_val_cat, X_test_cat, y_train_val_cat, y_test_cat = train_test_split(\n",
    "    X_cat, y_cat, test_size=0.25, random_state=42, stratify=y_cat)\n",
    "\n",
    "# === –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã ===\n",
    "n_splits = 5\n",
    "num_epochs = 45\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === –•—Ä–∞–Ω–∏–ª–∏—â–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===\n",
    "all_nn_logits = []\n",
    "all_cat_logits = []\n",
    "all_labels = []\n",
    "f1_scores_per_fold_nn = []\n",
    "f1_scores_per_fold_cat = []\n",
    "\n",
    "# === –ì—Ä–∞—Ñ–∏–∫–∏ –ø–æ —Ñ–æ–ª–¥–∞–º ===\n",
    "all_train_losses = []\n",
    "all_f1_scores = []\n",
    "all_val_losses = []\n",
    "all_val_f1_scores = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_val_nn, y_train_val_nn)):\n",
    "    y_val_fold = y_train_val_nn[val_idx]\n",
    "    values, counts = np.unique(y_val_fold, return_counts=True)\n",
    "    print(f\"\\nüîÅ Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ NN –¥–∞–Ω–Ω—ã—Ö\n",
    "    X_train_np_nn = X_train_val_nn.iloc[train_idx].values\n",
    "    X_val_np_nn = X_train_val_nn.iloc[val_idx].values\n",
    "    y_train_np_nn = y_train_val_nn[train_idx].astype(np.int64)\n",
    "    y_val_np_nn = y_train_val_nn[val_idx].astype(np.int64)\n",
    "\n",
    "    X_train_np_nn = normalize_signals(X_train_np_nn)\n",
    "    X_val_np_nn = normalize_signals(X_val_np_nn)\n",
    "\n",
    "    X_train_tensor_nn = torch.tensor(X_train_np_nn, dtype=torch.float32)\n",
    "    y_train_tensor_nn = torch.tensor(y_train_np_nn, dtype=torch.long)\n",
    "    X_val_tensor_nn = torch.tensor(X_val_np_nn, dtype=torch.float32)\n",
    "    y_val_tensor_nn = torch.tensor(y_val_np_nn, dtype=torch.long)\n",
    "\n",
    "    train_loader_nn = DataLoader(TensorDataset(X_train_tensor_nn, y_train_tensor_nn), batch_size=batch_size, shuffle=True)\n",
    "    val_loader_nn = DataLoader(TensorDataset(X_val_tensor_nn, y_val_tensor_nn), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Specnaz_gru_plus_norm(input_size=721, num_classes=6).to(device)\n",
    "    # criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.1)\n",
    "    criterion = FocalLoss(alpha=weights,gamma=1)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.0002)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=25, T_mult=1, eta_min=1e-4\n",
    "    )\n",
    "\n",
    "    # === –î–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ ===\n",
    "    train_losses = []\n",
    "    f1_scores = []\n",
    "    val_losses_per_epoch = []\n",
    "    val_f1_per_epoch = []\n",
    "    lrs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_epoch = []\n",
    "        for inputs, labels in train_loader_nn:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_epoch.append(loss.item())\n",
    "        scheduler.step()\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # === –í–∞–ª–∏–¥–∞—Ü–∏—è ===\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        val_loss_epoch = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader_nn:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss_epoch.append(loss.item())\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_train_loss = np.mean(train_loss_epoch)\n",
    "        avg_val_loss = np.mean(val_loss_epoch)\n",
    "        val_f1_nn = f1_score(val_targets, val_preds, average='weighted')\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses_per_epoch.append(avg_val_loss)\n",
    "        f1_scores.append(val_f1_nn)\n",
    "        val_f1_per_epoch.append(val_f1_nn)\n",
    "    plt.plot(lrs)\n",
    "    plt.title(\"Learning Rate Schedule\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"LR\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_val_losses.append(val_losses_per_epoch)\n",
    "    all_f1_scores.append(val_f1_per_epoch)\n",
    "    # === –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è ===\n",
    "    val_logits = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in val_loader_nn:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            val_logits.append(probs.cpu())\n",
    "\n",
    "    nn_fold_logits = torch.cat(val_logits).numpy()\n",
    "    all_nn_logits.append(nn_fold_logits)\n",
    "    \n",
    "    # === CatBoost ===\n",
    "    X_train_np_cat = X_train_val_cat.iloc[train_idx].values\n",
    "    X_val_np_cat = X_train_val_cat.iloc[val_idx].values\n",
    "    y_train_np_cat = y_train_val_cat[train_idx]\n",
    "    y_val_np_cat = y_train_val_cat[val_idx]\n",
    "\n",
    "    cat_model = CatBoostClassifier(verbose=0, iterations=2000, early_stopping_rounds=50,loss_function = 'MultiClass',eval_metric='MultiClass',random_seed=42)\n",
    "    cat_model.fit(X_train_np_cat, y_train_np_cat, eval_set=(X_val_np_cat, y_val_np_cat))\n",
    "    cat_probs = cat_model.predict_proba(X_val_np_cat)\n",
    "    cat_preds = np.argmax(cat_probs, axis=1)\n",
    "    cat_f1 = f1_score(y_val_np_cat, cat_preds, average='weighted')\n",
    "    all_cat_logits.append(cat_probs)\n",
    "\n",
    "    all_labels.append(y_val_np_nn)\n",
    "    f1_scores_per_fold_nn.append(val_f1_nn)\n",
    "    f1_scores_per_fold_cat.append(cat_f1)\n",
    "    torch.save(model.state_dict(), f\"nn_model_fold{fold}.pth\")\n",
    "    cat_model.save_model(f\"catboost_model_fold{fold}.cbm\")\n",
    "    print(f\"NN Report Fold {fold+1}:\\n\", classification_report(y_val_np_nn, np.argmax(nn_fold_logits, axis=1), digits=4))\n",
    "    print(f\"CatBoost Report Fold {fold+1}:\\n\", classification_report(y_val_np_cat, np.argmax(cat_probs, axis=1), digits=4))\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # –î–≤–∞ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞\n",
    "    plt.plot(all_train_losses[fold], label='Train Loss')\n",
    "    plt.plot(all_val_losses[fold], label='Val Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Fold {fold+1} - Loss per Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(all_f1_scores[fold], label='F1 Score', color='green')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"F1 \")\n",
    "    plt.title(f\"Fold {fold+1} - F1 per Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3e8ef6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9189    1.0000    0.9577        34\n",
      "           1     0.6667    0.8571    0.7500         7\n",
      "           2     0.9231    0.7059    0.8000        17\n",
      "           3     0.8000    0.6154    0.6957        13\n",
      "           4     0.6364    0.6364    0.6364        11\n",
      "           5     0.7273    0.8000    0.7619        20\n",
      "\n",
      "    accuracy                         0.8137       102\n",
      "   macro avg     0.7787    0.7691    0.7669       102\n",
      "weighted avg     0.8191    0.8137    0.8107       102\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8718    1.0000    0.9315        34\n",
      "           1     0.5556    0.7143    0.6250         7\n",
      "           2     0.8333    0.5882    0.6897        17\n",
      "           3     1.0000    0.7692    0.8696        13\n",
      "           4     0.9091    0.9091    0.9091        11\n",
      "           5     0.9048    0.9500    0.9268        20\n",
      "\n",
      "    accuracy                         0.8627       102\n",
      "   macro avg     0.8458    0.8218    0.8253       102\n",
      "weighted avg     0.8705    0.8627    0.8589       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_logits_nn_list = []\n",
    "X_test_nn_np = normalize_signals(X_test_nn.values)\n",
    "X_test_tensor = torch.tensor(X_test_nn_np, dtype=torch.float32).to(device)\n",
    "\n",
    "for fold in range(n_splits):\n",
    "    model = Specnaz_gru_plus_norm(input_size=721, num_classes=6).to(device)\n",
    "    model.load_state_dict(torch.load(f\"nn_model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    fold_logits = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_test_tensor), batch_size):\n",
    "            batch = X_test_tensor[i:i+batch_size]\n",
    "            output = model(batch)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            fold_logits.append(probs.cpu())\n",
    "\n",
    "    fold_logits = torch.cat(fold_logits).numpy()\n",
    "    test_logits_nn_list.append(fold_logits)\n",
    "nn_probs = np.mean(test_logits_nn_list, axis=0)\n",
    "\n",
    "cat_test_probs_list     = []\n",
    "for fold in range(n_splits):\n",
    "    model_cat = CatBoostClassifier()\n",
    "    model_cat.load_model(f\"catboost_model_fold{fold}.cbm\")\n",
    "    probs = model_cat.predict_proba(X_test_cat.values)\n",
    "    cat_test_probs_list.append(probs)\n",
    "cat_probs = np.mean(cat_test_probs_list, axis=0)\n",
    "\n",
    "nn_preds = np.argmax(nn_probs, axis=1)\n",
    "cat_preds = np.argmax(cat_probs, axis=1)\n",
    "# === –ú–µ—Ç–∫–∏ ===\n",
    "print(\"Meta Test Classification Report:\")\n",
    "print(classification_report(y_test_cat, nn_preds, digits=4))\n",
    "print(classification_report(y_test_cat, cat_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "00bd626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta_features(probs):\n",
    "    \"\"\"–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π\"\"\"\n",
    "    eps = 1e-8\n",
    "    top1 = np.max(probs, axis=1, keepdims=True)\n",
    "    top2 = np.partition(probs, -2, axis=1)[:, -2][:, None]\n",
    "    top2_gap = (top1 - top2) / (top1 + eps)  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞\n",
    "    \n",
    "    entropy = -np.sum(probs * np.log(probs + eps), axis=1, keepdims=True)\n",
    "    max_entropy = np.log(probs.shape[1])  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è\n",
    "    norm_entropy = entropy / max_entropy  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è [0,1]\n",
    "    \n",
    "    uncertainty = 1 - top1  # –ú–µ—Ä–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏\n",
    "    \n",
    "    return np.concatenate([\n",
    "        probs,                 # –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
    "        top2,\n",
    "        top2_gap,\n",
    "        norm_entropy,\n",
    "        uncertainty\n",
    "    ], axis=1)\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n",
    "meta_nn = [extract_meta_features(logits) for logits in all_nn_logits]\n",
    "meta_cat = [extract_meta_features(logits) for logits in all_cat_logits]\n",
    "\n",
    "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏ —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ–º –º–æ–¥–µ–ª–µ–π\n",
    "X_meta = np.concatenate([\n",
    "    np.concatenate(meta_nn, axis=0),\n",
    "    np.concatenate(meta_cat, axis=0) \n",
    "], axis=1)\n",
    "y_meta = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3bc7554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–∞–Ω—Å–∞–º–±–ª—å), —Å—Ä–µ–¥–Ω–∏–π F1=0.7642,–ª—É—á—à–∏–π(0.8006)\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–∞–Ω—Å–∞–º–±–ª—å), —Å—Ä–µ–¥–Ω–∏–π F1=0.7834,–ª—É—á—à–∏–π(0.8219)\n"
     ]
    }
   ],
   "source": [
    "def choose_best_or_ensemble(val_f1_per_fold, threshold=0.075): \n",
    "    best_fold_idx = np.argmax(val_f1_per_fold)\n",
    "    best_f1 = val_f1_per_fold[best_fold_idx] \n",
    "    mean_f1 = np.mean(val_f1_per_fold)\n",
    "    \n",
    "    # –ï—Å–ª–∏ –ª—É—á—à–∏–π —Ñ–æ–ª–¥ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ª—É—á—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ (–Ω–∞ threshold), —Ç–æ –≤—ã–±–∏—Ä–∞–µ–º –µ–≥–æ\n",
    "    if best_f1 - mean_f1 > threshold:\n",
    "        print(f\"–í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (—Ñ–æ–ª–¥ {best_fold_idx}) —Å F1={best_f1:.4f},—Å—Ä–µ–¥–Ω–∏–π({mean_f1:.4f})\")\n",
    "        return 'best_model', best_fold_idx\n",
    "    else:\n",
    "        print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–∞–Ω—Å–∞–º–±–ª—å), —Å—Ä–µ–¥–Ω–∏–π F1={mean_f1:.4f},–ª—É—á—à–∏–π({best_f1:.4f})\")\n",
    "        return 'ensemble', None\n",
    "    \n",
    "mode_nn, best_fold_nn_idx = choose_best_or_ensemble(f1_scores_per_fold_nn)\n",
    "mode_cat, best_fold_cat_idx = choose_best_or_ensemble(f1_scores_per_fold_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b2b8c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meta_test(mode_nn,mode_cat,best_fold_nn_idx,best_fold_cat_idx,X_test_nn,X_test_cat,device):\n",
    "    if mode_nn == 'best_model':\n",
    "        model_nn = Specnaz_gru_plus_norm(721,num_classes=6).to(device)\n",
    "        model_nn.load_state_dict(torch.load( f\"nn_model_fold{best_fold_nn_idx}.pth\"))\n",
    "        model_nn.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = torch.tensor(normalize_signals(X_test_nn.values),dtype=torch.float32).to(device)\n",
    "            outputs = model_nn(inputs)\n",
    "            nn_probs = torch.softmax(outputs,dim=1).cpu().numpy()\n",
    "    else:\n",
    "        test_logits_nn_list = []\n",
    "        X_test_nn_np = normalize_signals(X_test_nn.values)\n",
    "        X_test_tensor = torch.tensor(X_test_nn_np, dtype=torch.float32).to(device)\n",
    "\n",
    "        for fold in range(n_splits):\n",
    "            model = Specnaz_gru_plus_norm(input_size=721, num_classes=6).to(device)\n",
    "            model.load_state_dict(torch.load(f\"nn_model_fold{fold}.pth\"))\n",
    "            model.eval()\n",
    "\n",
    "            fold_logits = []\n",
    "            with torch.no_grad():\n",
    "                for i in range(0, len(X_test_tensor), batch_size):\n",
    "                    batch = X_test_tensor[i:i+batch_size]\n",
    "                    output = model(batch)\n",
    "                    probs = torch.softmax(output, dim=1)\n",
    "                    fold_logits.append(probs.cpu())\n",
    "\n",
    "            fold_logits = torch.cat(fold_logits).numpy()\n",
    "            test_logits_nn_list.append(fold_logits)\n",
    "        nn_probs = np.mean(test_logits_nn_list, axis=0)\n",
    "    \n",
    "    if mode_cat == 'best_model':\n",
    "        model_cat = CatBoostClassifier()\n",
    "        model_cat.load_model(f\"catboost_model_fold{best_fold_cat_idx}.cbm\")\n",
    "        cat_probs = cat_model.predict_proba(X_test_cat)\n",
    "    else:\n",
    "        cat_test_probs_list     = []\n",
    "        for fold in range(n_splits):\n",
    "            model_cat = CatBoostClassifier()\n",
    "            model_cat.load_model(f\"catboost_model_fold{fold}.cbm\")\n",
    "            probs = model_cat.predict_proba(X_test_cat.values)\n",
    "            cat_test_probs_list.append(probs)\n",
    "        cat_probs = np.mean(cat_test_probs_list, axis=0)\n",
    "    nn_meta = extract_meta_features(nn_probs)\n",
    "    cat_meta = extract_meta_features(cat_probs)\n",
    "    return np.concatenate([nn_meta,cat_meta],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1a68ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class meta_notfix(nn.Module):\n",
    "    def __init__(self, input=20, output=6):\n",
    "        super(meta_notfix, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),           \n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(256, output) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cf6a5ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 88.4984\n",
      "Epoch [1/20], Validation Loss: 8.4983, Validation Accuracy: 0.75%, F1-score: 0.7632\n",
      "Epoch [6/20], Train Loss: 43.1874\n",
      "Epoch [6/20], Validation Loss: 3.7167, Validation Accuracy: 0.87%, F1-score: 0.8669\n",
      "Epoch [11/20], Train Loss: 35.8374\n",
      "Epoch [11/20], Validation Loss: 2.8569, Validation Accuracy: 0.86%, F1-score: 0.8553\n",
      "Epoch [16/20], Train Loss: 32.1955\n",
      "Epoch [16/20], Validation Loss: 2.7405, Validation Accuracy: 0.86%, F1-score: 0.8563\n",
      "Epoch [20/20], Train Loss: 30.9933\n",
      "Epoch [20/20], Validation Loss: 2.6577, Validation Accuracy: 0.86%, F1-score: 0.8553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.9333    0.9032        30\n",
      "           1     0.8000    0.5714    0.6667         7\n",
      "           2     0.7857    0.7333    0.7586        15\n",
      "           3     0.8000    1.0000    0.8889        12\n",
      "           4     0.9000    0.9000    0.9000        10\n",
      "           5     0.9375    0.8333    0.8824        18\n",
      "\n",
      "    accuracy                         0.8587        92\n",
      "   macro avg     0.8497    0.8286    0.8333        92\n",
      "weighted avg     0.8599    0.8587    0.8553        92\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –û–±–µ—Ä–Ω–∏ X_meta –∏ y_meta –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    X_meta, y_meta, test_size=0.1, random_state=42, stratify=y_meta\n",
    ")\n",
    "X_meta_train_tensor = torch.tensor(X_meta_train, dtype=torch.float32)\n",
    "y_meta_train_tensor = torch.tensor(y_meta_train, dtype=torch.long)\n",
    "X_meta_val_tensor = torch.tensor(X_meta_val, dtype=torch.float32)\n",
    "y_meta_val_tensor = torch.tensor(y_meta_val, dtype=torch.long)\n",
    "\n",
    "meta_train_dataset = TensorDataset(X_meta_train_tensor, y_meta_train_tensor)\n",
    "meta_val_dataset = TensorDataset(X_meta_val_tensor, y_meta_val_tensor)\n",
    "\n",
    "meta_train_loader = DataLoader(meta_train_dataset, batch_size=16, shuffle=True,drop_last=False)\n",
    "meta_val_loader = DataLoader(meta_val_dataset, batch_size=16, shuffle=False,drop_last=False)\n",
    "# –û–±—ä—è–≤–∏ –º–æ–¥–µ–ª—å\n",
    "meta_model = meta_notfix(input=20, output=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = FocalLoss(gamma=2.5)\n",
    "optimizer = torch.optim.AdamW(meta_model.parameters(), lr=7e-5)\n",
    "\n",
    "\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_model_state = None\n",
    "num_epochs_meta = 20\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "for epoch in range(num_epochs_meta):\n",
    "    # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞\n",
    "    meta_model.train()\n",
    "    total_train_loss = 0\n",
    "    for inputs, labels in meta_train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = meta_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "    meta_model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in meta_val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = meta_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            val_preds.append(probs.cpu().numpy())\n",
    "            val_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    val_preds = np.concatenate(val_preds, axis=0)\n",
    "    val_labels = np.concatenate(val_labels, axis=0)\n",
    "    val_preds_classes = np.argmax(val_preds, axis=1)\n",
    "    val_accuracy = (val_preds_classes == val_labels).mean()\n",
    "    val_f1 = f1_score(val_labels, val_preds_classes, average='weighted')\n",
    "\n",
    "    train_losses.append(total_train_loss)\n",
    "    val_losses.append(total_val_loss)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_model_state = meta_model.state_dict()\n",
    "\n",
    "    if epoch%5 == 0 or epoch == num_epochs_meta-1:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs_meta}], Train Loss: {total_train_loss:.4f}\")\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs_meta}], Validation Loss: {total_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, F1-score: {val_f1:.4f}\")\n",
    "print(classification_report(val_labels, val_preds_classes, digits=4))\n",
    "\n",
    "epochs = range(1, num_epochs_meta + 1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# F1 Score\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, val_f1_scores, label='Validation F1 Score', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Validation F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cdd67540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    1.0000    0.9655        84\n",
      "           1     0.8095    0.9444    0.8718        18\n",
      "           2     0.9714    0.8095    0.8831        42\n",
      "           3     0.9667    0.8788    0.9206        33\n",
      "           4     0.9630    0.9630    0.9630        27\n",
      "           5     0.9608    0.9800    0.9703        50\n",
      "\n",
      "    accuracy                         0.9409       254\n",
      "   macro avg     0.9341    0.9293    0.9291       254\n",
      "weighted avg     0.9437    0.9409    0.9401       254\n",
      "\n",
      "Confusion Matrix:\n",
      " [[84  0  0  0  0  0]\n",
      " [ 1 17  0  0  0  0]\n",
      " [ 5  3 34  0  0  0]\n",
      " [ 0  1  1 29  1  1]\n",
      " [ 0  0  0  0 26  1]\n",
      " [ 0  0  0  1  0 49]]\n"
     ]
    }
   ],
   "source": [
    "X_metat = make_meta_test(mode_nn,mode_cat,best_fold_nn_idx,best_fold_cat_idx,X_test_nn,X_test_cat,device)\n",
    "meta_model.load_state_dict(best_model_state)\n",
    "meta_model.eval()\n",
    "X_meta_test_tensor = torch.tensor(X_metat, dtype=torch.float32).to(device)\n",
    "meta_preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_meta_test_tensor), batch_size):\n",
    "        batch = X_meta_test_tensor[i:i+batch_size]\n",
    "        out = meta_model(batch)\n",
    "        probs = torch.softmax(out, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        meta_preds.extend(pred.cpu().numpy())\n",
    "\n",
    "meta_preds = np.array(meta_preds)\n",
    "\n",
    "# === –ú–µ—Ç–∫–∏ ===\n",
    "print(\"Meta Test Classification Report:\")\n",
    "print(classification_report(y_test_cat, meta_preds, digits=4))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cat, meta_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
